{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFF_qFKayRtn",
        "outputId": "5791e146-05f8-411a-8069-95e09cecccc8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úì spaCy loaded successfully!\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "print(\"‚úì spaCy loaded successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "doc = [\"OMG!!! Just tried the new coffee at @StarCafe ‚òï It was AMAZING!!! üòç #BestCoffee #MorningVibes\", \"The product quality was excellent, but the shipping took way too long. Customer service wasn't very helpful either.\", \"Scientists Discover New Treatment for Alzheimer's Disease in Breakthrough Study\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Basic Text Preprocessing Function\n",
        "\n",
        "This function performs basic text cleaning using spaCy:\n",
        "- Converts text to lowercase\n",
        "- Removes stop words (common words like \"the\", \"is\", \"a\")\n",
        "- Removes punctuation\n",
        "- Lemmatizes words (converts to base form)\n",
        "- Keeps only alphabetic tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BZtGX4cZzD0e"
      },
      "outputs": [],
      "source": [
        "def preprocess_text(text):\n",
        "    \"\"\"\n",
        "    Preprocess text using spaCy.\n",
        "    Args:\n",
        "        text (str): Raw text to process\n",
        "    Returns:\n",
        "        list: List of cleaned lemmas (lowercase, no stop words, no punctuation)\n",
        "    \"\"\"\n",
        "    # Process text with spaCy\n",
        "    doc = nlp(text)\n",
        "    # Extract cleaned lemmas\n",
        "    cleaned = [\n",
        "        token.lemma_.lower()\n",
        "        for token in doc\n",
        "        if not token.is_stop and not token.is_punct and token.is_alpha\n",
        "    ]\n",
        "\n",
        "    return cleaned"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for text in doc:\n",
        "    print(\"Social Media Text:\")\n",
        "    print(f\"Original: {text}\")\n",
        "    print(f\"Cleaned: {preprocess_text(text)}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Advanced Text Preprocessing Function\n",
        "\n",
        "This function offers more flexibility with configurable preprocessing options:\n",
        "\n",
        "**Parameters:**\n",
        "- `remove_stop`: Toggle stop word removal\n",
        "- `use_lemma`: Choose between lemmatized or original tokens\n",
        "- `lowercase`: Control case normalization\n",
        "- `alpha_only`: Control whether to keep only alphabetic characters\n",
        "\n",
        "This allows for customized preprocessing based on your specific NLP task requirements."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZHFH2kZxzShS"
      },
      "outputs": [],
      "source": [
        "def preprocess_text_advanced(text, remove_stop=True, use_lemma=True, lowercase=True, alpha_only=True):\n",
        "    \"\"\"\n",
        "    Advanced preprocessing with configurable options.\n",
        "\n",
        "    Args:\n",
        "        text (str): Raw text to process\n",
        "        remove_stop (bool): Remove stop words if True\n",
        "        use_lemma (bool): Use lemmas if True, original text if False\n",
        "        lowercase (bool): Convert to lowercase if True\n",
        "        alpha_only (bool): Keep only alphabetic tokens if True\n",
        "\n",
        "    Returns:\n",
        "        list: List of processed tokens\n",
        "    \"\"\"\n",
        "    doc = nlp(text)\n",
        "\n",
        "    cleaned = []\n",
        "    for token in doc:\n",
        "        # Apply filters\n",
        "        if token.is_punct:\n",
        "            continue\n",
        "        if remove_stop and token.is_stop:\n",
        "            continue\n",
        "        if alpha_only and not token.is_alpha:\n",
        "            continue\n",
        "\n",
        "        # Choose lemma or original text\n",
        "        word = token.lemma_ if use_lemma else token.text\n",
        "\n",
        "        # Apply lowercase\n",
        "        if lowercase:\n",
        "            word = word.lower()\n",
        "\n",
        "        cleaned.append(word)\n",
        "\n",
        "    return cleaned"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Text from Social Media\n",
        "\n",
        "1.\n",
        "2.\n",
        "3.\n",
        "4.\n",
        "5.\n",
        "6.\n",
        "7.\n",
        "8.\n",
        "9.\n",
        "10. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xLn8Vio9z0a3"
      },
      "outputs": [],
      "source": [
        "for text in doc:\n",
        "    print(\"Original:\", text)\n",
        "    print(\"\\nDefault (all filters):\", preprocess_text_advanced(text))\n",
        "    print(\"Keep stop words:\", preprocess_text_advanced(text, remove_stop=False))\n",
        "    print(\"Original tokens (no lemma):\", preprocess_text_advanced(text, use_lemma=False))\n",
        "    print(\"Keep numbers:\", preprocess_text_advanced(text, alpha_only=False))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
